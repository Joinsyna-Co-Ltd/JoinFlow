#!/usr/bin/env python3
"""
JoinFlow - Multi-Agent RAG System
==============================================

A complete AI agent system with:
- Browser automation
- Code execution in sandbox
- Data processing
- Image understanding
- Knowledge base (RAG)
- User history storage

Usage:
    python main.py                     # Interactive chat mode
    python main.py --task "your task"  # Execute a single task
    python main.py --api               # Start API server
    python main.py --demo              # Run demo
"""

import argparse
import asyncio
import logging
import os
import sys
from typing import Optional

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def setup_environment():
    """Setup environment variables and dependencies"""
    # Check for API key
    if not os.environ.get("OPENAI_API_KEY"):
        api_key = os.environ.get("LLM_API_KEY")
        if api_key:
            os.environ["OPENAI_API_KEY"] = api_key
        else:
            logger.warning(
                "No OPENAI_API_KEY found. Set it with:\n"
                "  export OPENAI_API_KEY=your-key\n"
                "Or use a local LLM with LiteLLM."
            )


def create_system(
    with_memory: bool = True,
    with_rag: bool = True,
    collection: str = "joinflow_knowledge"
):
    """
    Create and configure the complete agent system.
    
    Returns:
        Tuple of (orchestrator, session_manager, task_queue)
    """
    from joinflow_agent import (
        Orchestrator, AgentConfig, 
        SessionManager, TaskQueue
    )
    
    # Create config
    config = AgentConfig(
        llm_model=os.environ.get("LLM_MODEL", "gpt-4o-mini"),
        llm_api_key=os.environ.get("OPENAI_API_KEY"),
        browser_headless=True,
        os_workspace="./workspace",
        verbose=True
    )
    
    # Create orchestrator
    orchestrator = Orchestrator(config=config)
    
    # Create session manager
    session_manager = SessionManager(
        storage_path="./sessions",
        session_timeout_hours=24
    )
    
    # Create task queue
    task_queue = TaskQueue(max_workers=4)
    
    # Setup Qdrant service (centralized management)
    qdrant_service = None
    try:
        from joinflow_core.qdrant_service import get_qdrant_service, QdrantConfig
        
        # Use environment variable for Qdrant URL
        qdrant_url = os.environ.get("QDRANT_URL", "http://localhost:6333")
        qdrant_config = QdrantConfig(
            url=qdrant_url,
            knowledge_collection=collection,
            cache_enabled=True  # Enable LLM response caching
        )
        
        qdrant_service = get_qdrant_service(qdrant_config)
        
        if qdrant_service.is_connected:
            logger.info(f"âœ… Qdrant connected at {qdrant_url}")
        elif qdrant_service.is_available:
            logger.info("âš ï¸ Qdrant using in-memory mode (data not persistent)")
        
    except ImportError as e:
        logger.warning(f"Qdrant service not available: {e}")
    except Exception as e:
        logger.warning(f"Failed to initialize Qdrant service: {e}")
    
    # Setup RAG if enabled
    if with_rag and qdrant_service and qdrant_service.is_available:
        try:
            from joinflow_index.qdrant_store import QdrantVectorStore
            from joinflow_index.config import QdrantConfig as IndexConfig
            from joinflow_rag.engine import RAGEngine
            from joinflow_core.cached_llm import CachedLLM
            
            # Use Qdrant service client and embedder
            store = QdrantVectorStore(
                IndexConfig(
                    collection=collection,
                    vector_dim=qdrant_service.config.vector_dim,
                    url=qdrant_service.config.url
                ),
                client=qdrant_service.client
            )
            
            embedder = qdrant_service.get_embedder()
            
            # Create cached LLM wrapper to reduce token consumption
            def llm_func(prompt):
                return orchestrator._llm_agent.execute(prompt).output
            
            cached_llm = CachedLLM(
                llm_func,
                model_name=os.environ.get("LLM_MODEL", "gpt-4o-mini"),
                cache_enabled=True,
                similarity_threshold=0.92
            )
            
            rag_engine = RAGEngine(
                embedder=embedder,
                store=store,
                llm=cached_llm.query  # Use cached LLM
            )
            
            orchestrator.set_rag_engine(rag_engine)
            logger.info("âœ… RAG engine initialized with caching")
            
        except ImportError as e:
            logger.warning(f"RAG dependencies not available: {e}")
        except Exception as e:
            logger.warning(f"Failed to initialize RAG: {e}")
    
    # Setup memory if enabled
    if with_memory and qdrant_service and qdrant_service.is_available:
        try:
            from joinflow_memory import HistoryStore, MemoryConfig
            
            embedder = qdrant_service.get_embedder()
            
            memory_config = MemoryConfig(
                url=qdrant_service.config.url,
                history_collection=qdrant_service.config.history_collection,
                task_collection=qdrant_service.config.tasks_collection,
                vector_dim=qdrant_service.config.vector_dim
            )
            
            memory_store = HistoryStore(
                embedder=embedder,
                config=memory_config,
                client=qdrant_service.client
            )
            
            orchestrator.set_memory_store(memory_store)
            logger.info("âœ… Memory store initialized")
            
        except ImportError as e:
            logger.warning(f"Memory dependencies not available: {e}")
        except Exception as e:
            logger.warning(f"Failed to initialize memory: {e}")
    
    return orchestrator, session_manager, task_queue


def interactive_chat(orchestrator, session_manager=None):
    """Run interactive chat session"""
    print("\n" + "="*60)
    print("ğŸ¤– JoinFlow - Agent System")
    print("="*60)
    print("\nå¯ç”¨çš„ Agent:")
    print("  ğŸŒ Browser - ç½‘é¡µæµè§ˆå’Œæœç´¢")
    print("  ğŸ¤– LLM     - æ–‡æœ¬ç”Ÿæˆå’Œæ¨ç†")
    print("  ğŸ’» OS      - æ–‡ä»¶å’Œç³»ç»Ÿæ“ä½œ")
    print("  ğŸ“ Code    - ä»£ç æ‰§è¡Œ")
    print("  ğŸ“Š Data    - æ•°æ®å¤„ç†åˆ†æ")
    print("  ğŸ‘ï¸  Vision  - å›¾ç‰‡ç†è§£")
    print("  ğŸ“š RAG     - çŸ¥è¯†åº“æ£€ç´¢")
    print("\nå‘½ä»¤:")
    print("  /quit, /exit - é€€å‡º")
    print("  /clear       - æ¸…é™¤å†å²")
    print("  /history     - æŸ¥çœ‹æ‰§è¡Œå†å²")
    print("  /agents      - æŸ¥çœ‹å¯ç”¨ Agent")
    print("  /help        - æ˜¾ç¤ºå¸®åŠ©")
    print("="*60 + "\n")
    
    session = None
    if session_manager:
        session = session_manager.create_session(system_prompt="ä½ æ˜¯ä¸€ä¸ªå¼ºå¤§çš„AIåŠ©æ‰‹")
    
    while True:
        try:
            user_input = input("ğŸ‘¤ You: ").strip()
            
            if not user_input:
                continue
            
            # Handle commands
            if user_input.lower() in ["/quit", "/exit", "exit", "quit"]:
                print("Goodbye! ğŸ‘‹")
                break
            
            if user_input.lower() == "/clear":
                orchestrator.clear_history()
                if session:
                    session.messages = []
                print("âœ… å†å²å·²æ¸…é™¤\n")
                continue
            
            if user_input.lower() == "/history":
                history = orchestrator.get_execution_history()
                if not history:
                    print("æš‚æ— æ‰§è¡Œå†å²\n")
                else:
                    for i, plan in enumerate(history[-5:], 1):
                        print(f"{i}. {plan.original_task[:50]}...")
                        for step in plan.steps:
                            status = "âœ…" if step.status == "completed" else "âŒ"
                            print(f"   {status} [{step.agent_type.value}] {step.description[:40]}...")
                print()
                continue
            
            if user_input.lower() == "/agents":
                agents = orchestrator.get_agents()
                print("å¯ç”¨çš„ Agent:")
                for name, agent in agents.items():
                    print(f"  - {name}: {agent.name}")
                print()
                continue
            
            if user_input.lower() == "/help":
                print("å‘½ä»¤: /quit, /clear, /history, /agents, /help")
                print("\nç¤ºä¾‹ä»»åŠ¡:")
                print("  - æœç´¢ä»Šå¤©çš„ç§‘æŠ€æ–°é—»")
                print("  - æ‰§è¡Œ Python ä»£ç : print('hello')")
                print("  - åˆ†æ data.csv æ–‡ä»¶")
                print("  - æè¿°è¿™å¼ å›¾ç‰‡ image.jpg")
                print()
                continue
            
            # Execute task
            print("\nğŸ¤” æ€è€ƒä¸­...\n")
            
            # Add to session
            if session:
                session.add_message("user", user_input)
            
            result = orchestrator.execute(user_input)
            
            print(f"ğŸ¤– Assistant: {result.output}\n")
            
            # Add response to session
            if session:
                session.add_message("assistant", result.output)
                session.total_tokens += result.tokens_used
            
            # Show execution info
            if result.data and result.data.get("steps"):
                print(f"   ğŸ“Š æ‰§è¡Œäº† {len(result.data['steps'])} ä¸ªæ­¥éª¤")
                for step in result.data['steps']:
                    status = "âœ…" if step.get('success', True) else "âŒ"
                    print(f"      {status} {step['description'][:50]}...")
            if result.tokens_used:
                print(f"   ğŸ”¢ Tokens: {result.tokens_used}")
            print()
            
        except KeyboardInterrupt:
            print("\n\nGoodbye! ğŸ‘‹")
            break
        except Exception as e:
            print(f"\nâŒ Error: {e}\n")
            logger.exception("Error in chat")


def run_api_server(orchestrator, session_manager, task_queue, host="0.0.0.0", port=8000, with_ui=True):
    """Run the API server with optional Web UI"""
    try:
        if with_ui:
            # Run with beautiful Web UI
            from web.server import run_server
            run_server(host=host, port=port)
        else:
            # Run API only
            from joinflow_agent import run_api
            
            print(f"\nğŸš€ Starting JoinFlow API server on http://{host}:{port}")
            print(f"   Documentation: http://localhost:{port}/docs")
            print("   Press Ctrl+C to stop\n")
            
            run_api(orchestrator, session_manager, task_queue, host=host, port=port)
        
    except ImportError as e:
        print(f"âŒ Required packages not installed: {e}")
        print("   Install with: pip install fastapi uvicorn jinja2")
        sys.exit(1)


def run_demo():
    """Run a demo showcasing all capabilities"""
    print("\n" + "="*60)
    print("ğŸ¬ JoinFlow åŠŸèƒ½æ¼”ç¤º")
    print("="*60 + "\n")
    
    orchestrator, _, _ = create_system(with_memory=True, with_rag=True)
    
    demos = [
        ("ğŸ’¬ å¯¹è¯", "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ èƒ½åšä»€ä¹ˆï¼Ÿ"),
        ("ğŸ” æœç´¢", "æœç´¢ Python 3.12 çš„æ–°ç‰¹æ€§"),
        ("ğŸ“ æ–‡ä»¶", "åˆ—å‡ºå½“å‰ç›®å½•çš„æ–‡ä»¶"),
        ("ğŸ“Š åˆ†æ", "åˆ†æä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•è¶‹åŠ¿"),
    ]
    
    for name, task in demos:
        print(f"\n{'='*40}")
        print(f"{name}: {task}")
        print('='*40)
        
        try:
            result = orchestrator.execute(task)
            output = result.output[:500]
            if len(result.output) > 500:
                output += "..."
            print(f"\nç»“æœ:\n{output}")
            
            if result.data and result.data.get("steps"):
                print(f"\næ‰§è¡Œäº† {len(result.data['steps'])} ä¸ªæ­¥éª¤")
        except Exception as e:
            print(f"Error: {e}")
        
        print()
    
    print("="*60)
    print("æ¼”ç¤ºå®Œæˆ!")
    print("="*60)


def main():
    """Main entry point"""
    parser = argparse.ArgumentParser(
        description="JoinFlow - Multi-Agent RAG System",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python main.py                    # äº¤äº’å¼èŠå¤©
  python main.py --task "æœç´¢æ–°é—»"  # æ‰§è¡Œå•ä¸ªä»»åŠ¡
  python main.py --api              # å¯åŠ¨ API æœåŠ¡å™¨
  python main.py --api --port 9000  # æŒ‡å®šç«¯å£
  python main.py --demo             # è¿è¡Œæ¼”ç¤º
        """
    )
    parser.add_argument(
        "--task", "-t",
        type=str,
        help="Execute a single task"
    )
    parser.add_argument(
        "--api",
        action="store_true",
        help="Start API server"
    )
    parser.add_argument(
        "--ui",
        action="store_true",
        help="Start Web UI server (includes API)"
    )
    parser.add_argument(
        "--api-only",
        action="store_true",
        help="Start API server without Web UI"
    )
    parser.add_argument(
        "--host",
        type=str,
        default="0.0.0.0",
        help="API server host"
    )
    parser.add_argument(
        "--port",
        type=int,
        default=8000,
        help="API server port"
    )
    parser.add_argument(
        "--demo",
        action="store_true",
        help="Run demo"
    )
    parser.add_argument(
        "--no-memory",
        action="store_true",
        help="Disable user history storage"
    )
    parser.add_argument(
        "--no-rag",
        action="store_true",
        help="Disable RAG knowledge base"
    )
    parser.add_argument(
        "--model",
        type=str,
        default="gpt-4o-mini",
        help="LLM model to use"
    )
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="Enable verbose logging"
    )
    
    args = parser.parse_args()
    
    # Setup
    setup_environment()
    os.environ["LLM_MODEL"] = args.model
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    if args.demo:
        run_demo()
    elif args.ui or args.api:
        orchestrator, session_manager, task_queue = create_system(
            with_memory=not args.no_memory,
            with_rag=not args.no_rag
        )
        with_ui = args.ui or (args.api and not args.api_only)
        run_api_server(orchestrator, session_manager, task_queue, args.host, args.port, with_ui=with_ui)
    elif args.task:
        orchestrator, _, _ = create_system(
            with_memory=not args.no_memory,
            with_rag=not args.no_rag
        )
        result = orchestrator.execute(args.task)
        print(result.output)
    else:
        orchestrator, session_manager, _ = create_system(
            with_memory=not args.no_memory,
            with_rag=not args.no_rag
        )
        interactive_chat(orchestrator, session_manager)


if __name__ == "__main__":
    main()
